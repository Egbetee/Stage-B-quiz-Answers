{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAGE C QUIZ CODE by EGBETOKUN KEHINDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3177"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP = 355\n",
    "FP = 1480\n",
    "TN = 120\n",
    "FN = 45\n",
    "\n",
    "precision =(TP/(TP+FP))\n",
    "recall = (TP/(TP+FN))\n",
    "f1 = round(2*((precision *recall)/(precision+recall)), 4)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall is:  90.0\n",
      "False Positive Rate:  4.0\n"
     ]
    }
   ],
   "source": [
    "#option 1\n",
    "TN = 96 \n",
    "FP = 4 \n",
    "FN = 10 \n",
    "TP = 90\n",
    "#CRITERIA 1: must have a recall rate of at least 80%\n",
    "recall = (TP/(TP+FN))*100\n",
    "#criteria 2: must have a false positive rate of 10% or less\n",
    "fpr = (FP/(FP+TN))*100\n",
    "#criteria 3: a false positive result is 5 times more expensive than a false negative result\n",
    "#i.e FN must outweigh FP\n",
    "print('recall is: ', recall)\n",
    "print('False Positive Rate: ', fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall is:  79.0\n",
      "False Positive Rate:  1.0\n"
     ]
    }
   ],
   "source": [
    "#option 2\n",
    "TN = 99 \n",
    "FP = 1 \n",
    "FN = 21 \n",
    "TP = 79\n",
    "#CRITERIA 1: must have a recall rate of at least 80%\n",
    "recall = (TP/(TP+FN))*100\n",
    "#criteria 2: must have a false positive rate of 10% or less\n",
    "fpr = (FP/(FP+TN))*100\n",
    "#criteria 3: a false positive result is 5 times more expensive than a false negative result\n",
    "#i.e FN must outweigh FP\n",
    "print('recall is: ', recall)\n",
    "print('False Positive Rate: ', fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall is:  82.0\n",
      "False Positive Rate:  2.0\n"
     ]
    }
   ],
   "source": [
    "#option 3\n",
    "TN = 98 \n",
    "FP = 2 \n",
    "FN = 18 \n",
    "TP = 82\n",
    "#CRITERIA 1: must have a recall rate of at least 80%\n",
    "recall = (TP/(TP+FN))*100\n",
    "#criteria 2: must have a false positive rate of 10% or less\n",
    "fpr = (FP/(FP+TN))*100\n",
    "#criteria 3: a false positive result is 5 times more expensive than a false negative result\n",
    "#i.e FN must outweigh FP\n",
    "print('recall is: ', recall)\n",
    "print('False Positive Rate: ', fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall is:  78.0\n",
      "False Positive Rate:  9.0\n"
     ]
    }
   ],
   "source": [
    "#option 4\n",
    "TN = 91 \n",
    "FP = 9 \n",
    "FN = 22 \n",
    "TP = 78\n",
    "#CRITERIA 1: must have a recall rate of at least 80%\n",
    "recall = (TP/(TP+FN))*100\n",
    "#criteria 2: must have a false positive rate of 10% or less\n",
    "fpr = (FP/(FP+TN))*100\n",
    "#criteria 3: cost effective, a false positive result is 5 times more expensive than a false negative result\n",
    "#i.e FN must outweigh FP\n",
    "print('recall is: ', recall)\n",
    "print('False Positive Rate: ', fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#option 1 and 3 satisfies criteria 1 and 2, \n",
    "#for criteria 3, option 1 has 4 FP that's equivalent to 20 FN with the current FN of 10 that's a total of 30\n",
    "#option 3 has 2 FP that's equivalent to 10 FN, with the current FN of 18 that's a total of 28 making it minimize cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data_for_UCI_named.csv')\n",
    "df = df.drop('stab', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('stabf', axis =1)\n",
    "y = df.stabf\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 1)\n",
    "#resetting all index\n",
    "x_train = x_train.reset_index(drop = True)\n",
    "x_test = x_test.reset_index(drop = True)\n",
    "y_train = y_train.reset_index(drop = True)\n",
    "y_test = y_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming the x_train and x_test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_scaled_train= scaler.fit_transform(x_train)\n",
    "x_scaled_test = scaler.transform(x_test)\n",
    "\n",
    "x_normalized_train =pd.DataFrame(x_scaled_train, columns = x_train.columns)\n",
    "x_normalized_test =pd.DataFrame(x_scaled_test, columns = x_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_normalized_train, y_train)\n",
    "new_predictions = log_reg.predict(x_normalized_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable     0.9191    0.8778    0.8980       712\n",
      "    unstable     0.9341    0.9573    0.9456      1288\n",
      "\n",
      "    accuracy                         0.9290      2000\n",
      "   macro avg     0.9266    0.9176    0.9218      2000\n",
      "weighted avg     0.9288    0.9290    0.9286      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rc = RandomForestClassifier(random_state = 1)\n",
    "rc.fit(x_normalized_train, y_train)\n",
    "rc_pred = rc.predict(x_normalized_test)\n",
    "print(classification_report(y_test, rc_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable     0.9206    0.8469    0.8822       712\n",
      "    unstable     0.9190    0.9596    0.9389      1288\n",
      "\n",
      "    accuracy                         0.9195      2000\n",
      "   macro avg     0.9198    0.9033    0.9105      2000\n",
      "weighted avg     0.9195    0.9195    0.9187      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#xgboost using gradient boosting\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(max_depth= 3, learning_rate= 0.1, random_state = 1)\n",
    "xgb.fit(x_normalized_train, y_train)\n",
    "xgb_pred = xgb.predict(x_normalized_test)\n",
    "print(classification_report(y_test, xgb_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable     0.9297    0.8919    0.9104       712\n",
      "    unstable     0.9415    0.9627    0.9520      1288\n",
      "\n",
      "    accuracy                         0.9375      2000\n",
      "   macro avg     0.9356    0.9273    0.9312      2000\n",
      "weighted avg     0.9373    0.9375    0.9372      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "light = LGBMClassifier(random_state = 1)\n",
    "light.fit(x_normalized_train, y_train)\n",
    "light_pred = light.predict(x_normalized_test)\n",
    "print(classification_report(y_test, light_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [50, 100, 300, 500, 1000]\n",
    "min_samples_split = [2, 3, 5, 7, 9]\n",
    "min_samples_leaf = [1, 2, 4, 6, 8]\n",
    "max_features = ['auto', 'sqrt', 'log2', None] \n",
    "hyperparameter_grid = {'n_estimators': n_estimators,\n",
    "                       'min_samples_leaf': min_samples_leaf,\n",
    "                       'min_samples_split': min_samples_split,\n",
    "                       'max_features': max_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   54.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable     0.9211    0.8694    0.8945       712\n",
      "    unstable     0.9300    0.9589    0.9442      1288\n",
      "\n",
      "    accuracy                         0.9270      2000\n",
      "   macro avg     0.9256    0.9141    0.9193      2000\n",
      "weighted avg     0.9268    0.9270    0.9265      2000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 8,\n",
       " 'max_features': None}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "tree = ExtraTreesClassifier(random_state = 1)\n",
    "rscv = RandomizedSearchCV(tree, hyperparameter_grid, cv = 5, n_iter = 10, scoring = 'accuracy', n_jobs = -1, verbose = 1, random_state=1)\n",
    "rscv.fit(x_normalized_train, y_train)\n",
    "rscv_pred = rscv.predict(x_normalized_test)\n",
    "print(classification_report(y_test, rscv_pred, digits=4))\n",
    "bt_params = rscv.best_params_\n",
    "bt_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable     0.9410    0.8511    0.8938       712\n",
      "    unstable     0.9218    0.9705    0.9455      1288\n",
      "\n",
      "    accuracy                         0.9280      2000\n",
      "   macro avg     0.9314    0.9108    0.9197      2000\n",
      "weighted avg     0.9287    0.9280    0.9271      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#extra tree classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "tree = ExtraTreesClassifier(random_state = 1)\n",
    "tree.fit(x_normalized_train, y_train)\n",
    "tree_pred = tree.predict(x_normalized_test)\n",
    "print(classification_report(y_test, tree_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable     0.9211    0.8694    0.8945       712\n",
      "    unstable     0.9300    0.9589    0.9442      1288\n",
      "\n",
      "    accuracy                         0.9270      2000\n",
      "   macro avg     0.9256    0.9141    0.9193      2000\n",
      "weighted avg     0.9268    0.9270    0.9265      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_new = ExtraTreesClassifier(random_state = 1)\n",
    "tree_new.fit(x_normalized_train, y_train)\n",
    "rscv_new = RandomizedSearchCV(tree_new, hyperparameter_grid, random_state=1)\n",
    "rscv_new.fit(x_normalized_train, y_train)\n",
    "rscv_pred_new = rscv_new.predict(x_normalized_test)\n",
    "print(classification_report(y_test, rscv_pred_new, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>features</th>\n",
       "      <td>0.117397</td>\n",
       "      <td>0.118445</td>\n",
       "      <td>0.113169</td>\n",
       "      <td>0.115466</td>\n",
       "      <td>0.039507</td>\n",
       "      <td>0.040371</td>\n",
       "      <td>0.040706</td>\n",
       "      <td>0.040579</td>\n",
       "      <td>0.089783</td>\n",
       "      <td>0.093676</td>\n",
       "      <td>0.096883</td>\n",
       "      <td>0.094019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tau1      tau2      tau3      tau4        p1        p2  \\\n",
       "features  0.117397  0.118445  0.113169  0.115466  0.039507  0.040371   \n",
       "\n",
       "                p3        p4        g1        g2        g3        g4  \n",
       "features  0.040706  0.040579  0.089783  0.093676  0.096883  0.094019  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = tree_new.feature_importances_\n",
    "feature_importance = feature.reshape(1,12)\n",
    "features = pd.DataFrame(feature_importance, columns = x_train.columns, index=['features'])\n",
    "features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
